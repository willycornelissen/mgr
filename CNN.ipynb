{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Merge\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.pooling import MaxPooling1D\n",
    "from keras.layers.pooling import GlobalMaxPooling1D\n",
    "from keras.layers.pooling import GlobalAveragePooling1D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 100\n",
    "exec_times = 5\n",
    "augment_factor = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from numpy file\n",
    "songs =  np.load('data/features.npy')\n",
    "genres =  np.load('data/label.npy')\n",
    "\n",
    "# Split the dataset into training and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "  songs, genres, test_size=0.1, stratify=genres)\n",
    "\n",
    "# Split training set into training and validation\n",
    "X_train, X_Val, y_train, y_val = train_test_split(\n",
    "  X_train, y_train, test_size=1/6, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitsongs_melspect(X, y):\n",
    "    temp_X = []\n",
    "    temp_y = []\n",
    "\n",
    "    for i, song in enumerate(X):\n",
    "      song_slipted = np.split(song, augment_factor)\n",
    "      for s in song_slipted:\n",
    "        temp_X.append(s)\n",
    "        temp_y.append(y[i])\n",
    "\n",
    "    temp_X = np.array(temp_X)\n",
    "    temp_y = np.array(temp_y)\n",
    "\n",
    "    return temp_X, temp_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the train, test and validation data in size 128x128\n",
    "X_Val, y_val = splitsongs_melspect(X_Val, y_val)\n",
    "X_test, y_test = splitsongs_melspect(X_test, y_test)\n",
    "X_train, y_train = splitsongs_melspect(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = 3\n",
    "activation_func = Activation('relu')\n",
    "input_shape = (128, 128)\n",
    "inputs = Input(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional block_1\n",
    "conv1 = Conv1D(32, kernel_size)(inputs)\n",
    "act1 = activation_func(conv1)\n",
    "bn1 = BatchNormalization()(act1)\n",
    "pool1 = MaxPooling1D(pool_size=2, strides=2)(bn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional block_2\n",
    "conv2 = Conv1D(64, kernel_size)(pool1)\n",
    "act2 = activation_func(conv2)\n",
    "bn2 = BatchNormalization()(act2)\n",
    "pool2 = MaxPooling1D(pool_size=2, strides=2)(bn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional block_3\n",
    "conv3 = Conv1D(128, kernel_size)(pool2)\n",
    "act3 = activation_func(conv3)\n",
    "bn3 = BatchNormalization()(act3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Layers\n",
    "gmaxpl = GlobalMaxPooling1D()(bn3)\n",
    "gmeanpl = GlobalAveragePooling1D()(bn3)\n",
    "mergedlayer = concatenate([gmaxpl, gmeanpl], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular MLP\n",
    "dense1 = Dense(512,\n",
    "    kernel_initializer='glorot_normal',\n",
    "    bias_initializer='glorot_normal')(mergedlayer)\n",
    "actmlp = activation_func(dense1)\n",
    "reg = Dropout(0.5)(actmlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense2 = Dense(512,\n",
    "    kernel_initializer='glorot_normal',\n",
    "    bias_initializer='glorot_normal')(reg)\n",
    "actmlp = activation_func(dense2)\n",
    "reg = Dropout(0.5)(actmlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense2 = Dense(10, activation='softmax')(reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = Model(inputs=[inputs], outputs=[dense2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train shape: (7500, 128, 128)\n",
      "Validation shape: (1500, 128, 128)\n",
      "Test shape: (1000, 128, 128)\n",
      "\n",
      "Size of the CNN: 443498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTrain shape: {0}\".format(X_train.shape))\n",
    "print(\"Validation shape: {0}\".format(X_Val.shape))\n",
    "print(\"Test shape: {0}\\n\".format(X_test.shape))\n",
    "print(\"Size of the CNN: %s\\n\" % cnn.count_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 128, 128)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 126, 32)      12320       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       multiple             0           conv1d_4[0][0]                   \n",
      "                                                                 conv1d_5[0][0]                   \n",
      "                                                                 conv1d_6[0][0]                   \n",
      "                                                                 dense_4[0][0]                    \n",
      "                                                                 dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 126, 32)      128         activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 63, 32)       0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 61, 64)       6208        max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 61, 64)       256         activation_2[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 30, 64)       0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 28, 128)      24704       max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 28, 128)      512         activation_2[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 128)          0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 128)          0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 256)          0           global_max_pooling1d_2[0][0]     \n",
      "                                                                 global_average_pooling1d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 512)          131584      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 512)          0           activation_2[3][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 512)          262656      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 512)          0           activation_2[4][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 10)           5130        dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 443,498\n",
      "Trainable params: 443,050\n",
      "Non-trainable params: 448\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "sgd = keras.optimizers.SGD(lr=0.001, momentum=0.9, decay=1e-5, nesterov=True)\n",
    "adam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiler for the model\n",
    "cnn.compile(loss=keras.losses.categorical_crossentropy,\n",
    "  optimizer=sgd,\n",
    "  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stop\n",
    "earlystop = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "  min_delta=0,\n",
    "  patience=2,\n",
    "  verbose=0,\n",
    "  mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7500 samples, validate on 1500 samples\n",
      "Epoch 1/100\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 2.1237 - acc: 0.2389 - val_loss: 1.7405 - val_acc: 0.3733\n",
      "Epoch 2/100\n",
      "7500/7500 [==============================] - 15s 2ms/step - loss: 1.7722 - acc: 0.3539 - val_loss: 1.5586 - val_acc: 0.4500\n",
      "Epoch 3/100\n",
      "7500/7500 [==============================] - 15s 2ms/step - loss: 1.6355 - acc: 0.4120 - val_loss: 1.4790 - val_acc: 0.4713\n",
      "Epoch 4/100\n",
      "7500/7500 [==============================] - 15s 2ms/step - loss: 1.5344 - acc: 0.4452 - val_loss: 1.4270 - val_acc: 0.5007\n",
      "Epoch 5/100\n",
      "7500/7500 [==============================] - 15s 2ms/step - loss: 1.4411 - acc: 0.4813 - val_loss: 1.3647 - val_acc: 0.5200\n",
      "Epoch 6/100\n",
      "7500/7500 [==============================] - 15s 2ms/step - loss: 1.3659 - acc: 0.5169 - val_loss: 1.3078 - val_acc: 0.5333\n",
      "Epoch 7/100\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 1.3153 - acc: 0.5392 - val_loss: 1.3173 - val_acc: 0.5433\n",
      "Epoch 8/100\n",
      "7500/7500 [==============================] - 15s 2ms/step - loss: 1.2495 - acc: 0.5579 - val_loss: 1.2898 - val_acc: 0.5400\n",
      "Epoch 9/100\n",
      "7500/7500 [==============================] - 15s 2ms/step - loss: 1.2094 - acc: 0.5777 - val_loss: 1.3165 - val_acc: 0.5393\n",
      "Epoch 10/100\n",
      "7500/7500 [==============================] - 15s 2ms/step - loss: 1.1573 - acc: 0.5973 - val_loss: 1.2797 - val_acc: 0.5580\n",
      "Epoch 11/100\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 1.0925 - acc: 0.6223 - val_loss: 1.2411 - val_acc: 0.5633\n",
      "Epoch 12/100\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 1.0787 - acc: 0.6280 - val_loss: 1.1914 - val_acc: 0.5887\n",
      "Epoch 13/100\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 1.0307 - acc: 0.6505 - val_loss: 1.2202 - val_acc: 0.5793\n",
      "Epoch 14/100\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 1.0021 - acc: 0.6609 - val_loss: 1.2533 - val_acc: 0.5693\n",
      "Epoch 15/100\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 0.9455 - acc: 0.6755 - val_loss: 1.2601 - val_acc: 0.5793\n",
      "Epoch 16/100\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 0.9405 - acc: 0.6817 - val_loss: 1.2240 - val_acc: 0.5920\n",
      "Epoch 17/100\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 0.9091 - acc: 0.6941 - val_loss: 1.2501 - val_acc: 0.5793\n",
      "Epoch 18/100\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 0.8692 - acc: 0.7019 - val_loss: 1.2755 - val_acc: 0.5880\n",
      "Epoch 19/100\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 0.8419 - acc: 0.7175 - val_loss: 1.2850 - val_acc: 0.5933\n",
      "Epoch 20/100\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 0.8338 - acc: 0.7180 - val_loss: 1.2064 - val_acc: 0.5913\n",
      "Epoch 21/100\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 0.8076 - acc: 0.7232 - val_loss: 1.2303 - val_acc: 0.5987\n",
      "Epoch 22/100\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 0.7798 - acc: 0.7384 - val_loss: 1.3459 - val_acc: 0.5733\n",
      "Epoch 23/100\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 0.7489 - acc: 0.7489 - val_loss: 1.3255 - val_acc: 0.5740\n",
      "Epoch 24/100\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 0.7432 - acc: 0.7525 - val_loss: 1.3296 - val_acc: 0.5700\n",
      "Epoch 25/100\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 0.7159 - acc: 0.7575 - val_loss: 1.3633 - val_acc: 0.5793\n",
      "Epoch 26/100\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 0.6870 - acc: 0.7712 - val_loss: 1.3204 - val_acc: 0.5780\n",
      "Epoch 27/100\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 0.6998 - acc: 0.7639 - val_loss: 1.3595 - val_acc: 0.5960\n",
      "Epoch 28/100\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 0.6761 - acc: 0.7723 - val_loss: 1.2941 - val_acc: 0.5733\n",
      "Epoch 29/100\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 0.6475 - acc: 0.7827 - val_loss: 1.3598 - val_acc: 0.5940\n",
      "Epoch 30/100\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 0.6429 - acc: 0.7847 - val_loss: 1.3435 - val_acc: 0.5987\n",
      "Epoch 31/100\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 0.6157 - acc: 0.7993 - val_loss: 1.3698 - val_acc: 0.6060\n",
      "Epoch 32/100\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 0.6050 - acc: 0.8020 - val_loss: 1.3107 - val_acc: 0.5893\n",
      "Epoch 33/100\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 0.5916 - acc: 0.8024 - val_loss: 1.3662 - val_acc: 0.6073\n",
      "Epoch 34/100\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 0.5867 - acc: 0.8085 - val_loss: 1.3140 - val_acc: 0.5987\n",
      "Epoch 35/100\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 0.5597 - acc: 0.8127 - val_loss: 1.3361 - val_acc: 0.5913\n",
      "Epoch 36/100\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 0.5542 - acc: 0.8148 - val_loss: 1.2992 - val_acc: 0.6240\n",
      "Epoch 37/100\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 0.5449 - acc: 0.8212 - val_loss: 1.2830 - val_acc: 0.6167\n",
      "Epoch 38/100\n",
      "7500/7500 [==============================] - 18s 2ms/step - loss: 0.5222 - acc: 0.8284 - val_loss: 1.3846 - val_acc: 0.5873\n",
      "Epoch 39/100\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 0.5366 - acc: 0.8261 - val_loss: 1.4676 - val_acc: 0.5847\n",
      "Epoch 40/100\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 0.5224 - acc: 0.8272 - val_loss: 1.4598 - val_acc: 0.5720\n",
      "Epoch 41/100\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 0.4851 - acc: 0.8417 - val_loss: 1.4517 - val_acc: 0.6073\n",
      "Epoch 42/100\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 0.4738 - acc: 0.8441 - val_loss: 1.3168 - val_acc: 0.6060\n",
      "Epoch 43/100\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 0.4773 - acc: 0.8425 - val_loss: 1.4087 - val_acc: 0.6013\n",
      "Epoch 44/100\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 0.4601 - acc: 0.8496 - val_loss: 1.4503 - val_acc: 0.6127\n",
      "Epoch 45/100\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 0.4615 - acc: 0.8447 - val_loss: 1.3924 - val_acc: 0.6427\n",
      "Epoch 46/100\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 0.4550 - acc: 0.8495 - val_loss: 1.4159 - val_acc: 0.6160\n",
      "Epoch 47/100\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 0.4527 - acc: 0.8527 - val_loss: 1.4120 - val_acc: 0.6207\n",
      "Epoch 48/100\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 0.4358 - acc: 0.8536 - val_loss: 1.3882 - val_acc: 0.6307\n",
      "Epoch 49/100\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 0.4132 - acc: 0.8620 - val_loss: 1.5686 - val_acc: 0.6033\n",
      "Epoch 50/100\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 0.4188 - acc: 0.8632 - val_loss: 1.5709 - val_acc: 0.6187\n",
      "Epoch 51/100\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 0.4111 - acc: 0.8632 - val_loss: 1.4068 - val_acc: 0.6187\n",
      "Epoch 52/100\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 0.3956 - acc: 0.8623 - val_loss: 1.5112 - val_acc: 0.6207\n",
      "Epoch 53/100\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 0.4093 - acc: 0.8669 - val_loss: 1.4961 - val_acc: 0.6267\n",
      "Epoch 54/100\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 0.3823 - acc: 0.8777 - val_loss: 1.5263 - val_acc: 0.6120\n",
      "Epoch 55/100\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 0.3728 - acc: 0.8731 - val_loss: 1.5842 - val_acc: 0.5900\n",
      "Epoch 56/100\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 0.3685 - acc: 0.8793 - val_loss: 1.6516 - val_acc: 0.5960\n",
      "Epoch 57/100\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 0.3830 - acc: 0.8692 - val_loss: 1.5687 - val_acc: 0.5887\n",
      "Epoch 58/100\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 0.3689 - acc: 0.8833 - val_loss: 1.4901 - val_acc: 0.6233\n",
      "Epoch 59/100\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 0.3603 - acc: 0.8851 - val_loss: 1.7025 - val_acc: 0.5560\n",
      "Epoch 60/100\n",
      "7500/7500 [==============================] - 13s 2ms/step - loss: 0.3652 - acc: 0.8777 - val_loss: 1.5228 - val_acc: 0.5960\n",
      "Epoch 61/100\n",
      "7500/7500 [==============================] - 15s 2ms/step - loss: 0.3586 - acc: 0.8797 - val_loss: 1.4650 - val_acc: 0.6460\n",
      "Epoch 62/100\n",
      "7500/7500 [==============================] - 15s 2ms/step - loss: 0.3267 - acc: 0.8971 - val_loss: 1.5870 - val_acc: 0.6207\n",
      "Epoch 63/100\n",
      "7500/7500 [==============================] - 12s 2ms/step - loss: 0.3217 - acc: 0.8944 - val_loss: 1.7154 - val_acc: 0.5993\n",
      "Epoch 64/100\n",
      "7500/7500 [==============================] - 12s 2ms/step - loss: 0.3252 - acc: 0.8973 - val_loss: 1.6611 - val_acc: 0.5880\n",
      "Epoch 65/100\n",
      "7500/7500 [==============================] - 12s 2ms/step - loss: 0.3008 - acc: 0.9040 - val_loss: 1.6267 - val_acc: 0.6227\n",
      "Epoch 66/100\n",
      "7500/7500 [==============================] - 15s 2ms/step - loss: 0.3233 - acc: 0.8921 - val_loss: 1.5360 - val_acc: 0.6200\n",
      "Epoch 67/100\n",
      "7500/7500 [==============================] - 15s 2ms/step - loss: 0.3206 - acc: 0.8956 - val_loss: 1.5806 - val_acc: 0.6200\n",
      "Epoch 68/100\n",
      "7500/7500 [==============================] - 14s 2ms/step - loss: 0.3232 - acc: 0.8959 - val_loss: 1.5600 - val_acc: 0.6247\n",
      "Epoch 69/100\n",
      "7500/7500 [==============================] - 15s 2ms/step - loss: 0.3152 - acc: 0.8957 - val_loss: 1.6109 - val_acc: 0.6113\n",
      "Epoch 70/100\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 0.3040 - acc: 0.9053 - val_loss: 1.7058 - val_acc: 0.5953\n",
      "Epoch 71/100\n",
      "7500/7500 [==============================] - 19s 3ms/step - loss: 0.3054 - acc: 0.9041 - val_loss: 1.5727 - val_acc: 0.6173\n",
      "Epoch 72/100\n",
      "7500/7500 [==============================] - 19s 3ms/step - loss: 0.3035 - acc: 0.9049 - val_loss: 1.6025 - val_acc: 0.6140\n",
      "Epoch 73/100\n",
      "7500/7500 [==============================] - 20s 3ms/step - loss: 0.2802 - acc: 0.9104 - val_loss: 1.7839 - val_acc: 0.5680\n",
      "Epoch 74/100\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 0.2740 - acc: 0.9131 - val_loss: 1.7104 - val_acc: 0.5733\n",
      "Epoch 75/100\n",
      "7500/7500 [==============================] - 11s 1ms/step - loss: 0.2819 - acc: 0.9087 - val_loss: 1.7069 - val_acc: 0.6067\n",
      "Epoch 76/100\n",
      "7500/7500 [==============================] - 14s 2ms/step - loss: 0.2910 - acc: 0.9052 - val_loss: 1.7664 - val_acc: 0.5867\n",
      "Epoch 77/100\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 0.2627 - acc: 0.9164 - val_loss: 1.7390 - val_acc: 0.6080\n",
      "Epoch 78/100\n",
      "7500/7500 [==============================] - 15s 2ms/step - loss: 0.2681 - acc: 0.9135 - val_loss: 1.8115 - val_acc: 0.6160\n",
      "Epoch 79/100\n",
      "7500/7500 [==============================] - 10s 1ms/step - loss: 0.2648 - acc: 0.9164 - val_loss: 1.7939 - val_acc: 0.5813\n",
      "Epoch 80/100\n",
      "7500/7500 [==============================] - 11s 1ms/step - loss: 0.2491 - acc: 0.9184 - val_loss: 1.9601 - val_acc: 0.5660\n",
      "Epoch 81/100\n",
      "7500/7500 [==============================] - 15s 2ms/step - loss: 0.2827 - acc: 0.9101 - val_loss: 1.7980 - val_acc: 0.6073\n",
      "Epoch 82/100\n",
      "7500/7500 [==============================] - 14s 2ms/step - loss: 0.2602 - acc: 0.9155 - val_loss: 1.8333 - val_acc: 0.5787\n",
      "Epoch 83/100\n",
      "7500/7500 [==============================] - 12s 2ms/step - loss: 0.2461 - acc: 0.9239 - val_loss: 1.7811 - val_acc: 0.6047\n",
      "Epoch 84/100\n",
      "7500/7500 [==============================] - 13s 2ms/step - loss: 0.2493 - acc: 0.9235 - val_loss: 1.7182 - val_acc: 0.6200\n",
      "Epoch 85/100\n",
      "7500/7500 [==============================] - 14s 2ms/step - loss: 0.2445 - acc: 0.9237 - val_loss: 1.7605 - val_acc: 0.6273\n",
      "Epoch 86/100\n",
      "7500/7500 [==============================] - 14s 2ms/step - loss: 0.2467 - acc: 0.9244 - val_loss: 1.7926 - val_acc: 0.5853\n",
      "Epoch 87/100\n",
      "7500/7500 [==============================] - 13s 2ms/step - loss: 0.2421 - acc: 0.9216 - val_loss: 1.9043 - val_acc: 0.5653\n",
      "Epoch 88/100\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 0.2542 - acc: 0.9197 - val_loss: 1.8789 - val_acc: 0.6047\n",
      "Epoch 89/100\n",
      "7500/7500 [==============================] - 12s 2ms/step - loss: 0.2322 - acc: 0.9244 - val_loss: 1.7142 - val_acc: 0.6120\n",
      "Epoch 90/100\n",
      "7500/7500 [==============================] - 10s 1ms/step - loss: 0.2382 - acc: 0.9248 - val_loss: 1.8438 - val_acc: 0.5940\n",
      "Epoch 91/100\n",
      "7500/7500 [==============================] - 13s 2ms/step - loss: 0.2343 - acc: 0.9236 - val_loss: 1.8060 - val_acc: 0.6120\n",
      "Epoch 92/100\n",
      "7500/7500 [==============================] - 15s 2ms/step - loss: 0.2372 - acc: 0.9243 - val_loss: 1.7378 - val_acc: 0.6187\n",
      "Epoch 93/100\n",
      "7500/7500 [==============================] - 15s 2ms/step - loss: 0.2260 - acc: 0.9288 - val_loss: 1.8294 - val_acc: 0.6173\n",
      "Epoch 94/100\n",
      "7500/7500 [==============================] - 11s 1ms/step - loss: 0.2290 - acc: 0.9295 - val_loss: 1.9144 - val_acc: 0.5967\n",
      "Epoch 95/100\n",
      "7500/7500 [==============================] - 13s 2ms/step - loss: 0.2223 - acc: 0.9283 - val_loss: 1.8452 - val_acc: 0.6100\n",
      "Epoch 96/100\n",
      "7500/7500 [==============================] - 13s 2ms/step - loss: 0.2199 - acc: 0.9299 - val_loss: 1.8464 - val_acc: 0.6060\n",
      "Epoch 97/100\n",
      "7500/7500 [==============================] - 15s 2ms/step - loss: 0.2057 - acc: 0.9368 - val_loss: 1.7951 - val_acc: 0.6233\n",
      "Epoch 98/100\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 0.2130 - acc: 0.9328 - val_loss: 1.8813 - val_acc: 0.6033\n",
      "Epoch 99/100\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 0.2149 - acc: 0.9345 - val_loss: 1.7955 - val_acc: 0.6027\n",
      "Epoch 100/100\n",
      "7500/7500 [==============================] - 17s 2ms/step - loss: 0.1948 - acc: 0.9367 - val_loss: 1.8123 - val_acc: 0.6160\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history = cnn.fit(X_train, y_train,\n",
    "  batch_size=batch_size,\n",
    "  epochs=epochs,\n",
    "  verbose=1,\n",
    "  validation_data=(X_Val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cnn.evaluate(X_test, y_test, verbose=0)\n",
    "score_val = cnn.evaluate(X_Val, y_val, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.645\n",
      "Score Validation: 0.6160000002384186\n"
     ]
    }
   ],
   "source": [
    "print(\"Score:\", score[1])\n",
    "print(\"Score Validation:\", score_val[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.save('model/cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
