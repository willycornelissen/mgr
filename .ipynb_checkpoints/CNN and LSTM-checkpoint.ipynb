{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa as lbr\n",
    "import os\n",
    "import _pickle\n",
    "\n",
    "from keras.callbacks import Callback\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop,Adam\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense, Lambda, Dropout, Activation, LSTM, TimeDistributed, Convolution1D, MaxPooling1D,Conv1D,AveragePooling1D, Flatten,GlobalAveragePooling1D,GlobalMaxPooling1D,concatenate\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENRES = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal',\n",
    "        'pop', 'reggae', 'rock']\n",
    "WINDOW_SIZE = 2048\n",
    "WINDOW_STRIDE = WINDOW_SIZE // 2\n",
    "N_MELS = 128\n",
    "MEL_KWARGS = {\n",
    "    'n_fft': WINDOW_SIZE,\n",
    "    'hop_length': WINDOW_STRIDE,\n",
    "    'n_mels': N_MELS\n",
    "}\n",
    "TRACK_COUNT = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_track(filename, enforce_shape=None):\n",
    "    new_input, sample_rate = lbr.load(filename, mono=True)\n",
    "    features = lbr.feature.melspectrogram(new_input, **MEL_KWARGS).T\n",
    "\n",
    "    if enforce_shape is not None:\n",
    "        if features.shape[0] < enforce_shape[0]:\n",
    "            delta_shape = (enforce_shape[0] - features.shape[0],\n",
    "                    enforce_shape[1])\n",
    "            features = np.append(features, np.zeros(delta_shape), axis=0)\n",
    "        elif features.shape[0] > enforce_shape[0]:\n",
    "            features = features[: enforce_shape[0], :]\n",
    "\n",
    "    features[features == 0] = 1e-6\n",
    "    return (np.log(features), float(new_input.shape[0]) / sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_shape(dataset_path):\n",
    "    tmp_features, _ = load_track(os.path.join(dataset_path,\n",
    "        'blues/blues.00000.au'))\n",
    "    return tmp_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_data(dataset_path):\n",
    "    '''\n",
    "    Collects data from the GTZAN dataset into a pickle. Computes a Mel-scaled\n",
    "    power spectrogram for each track.\n",
    "\n",
    "    :param dataset_path: path to the GTZAN dataset directory\n",
    "    :returns: triple (x, y, track_paths) where x is a matrix containing\n",
    "        extracted features, y is a one-hot matrix of genre labels and\n",
    "        track_paths is a dict of absolute track paths indexed by row indices in\n",
    "        the x and y matrices\n",
    "    '''\n",
    "    default_shape = get_default_shape(dataset_path)\n",
    "    x = np.zeros((TRACK_COUNT,) + default_shape, dtype=np.float32)\n",
    "    y = np.zeros((TRACK_COUNT, len(GENRES)), dtype=np.float32)\n",
    "    track_paths = {}\n",
    "\n",
    "    for (genre_index, genre_name) in enumerate(GENRES):\n",
    "        print(\"Processing\", genre_name)\n",
    "        for i in range(TRACK_COUNT // len(GENRES)):\n",
    "            file_name = '{}/{}.000{}.au'.format(genre_name,\n",
    "                    genre_name, str(i).zfill(2))\n",
    "            path = os.path.join(dataset_path, file_name)\n",
    "            track_index = genre_index  * (TRACK_COUNT // len(GENRES)) + i\n",
    "            x[track_index], _ = load_track(path, default_shape)\n",
    "            y[track_index, genre_index] = 1\n",
    "            track_paths[track_index] = os.path.abspath(path)\n",
    "    return (x, y, track_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model(dataset_path):\n",
    "    (x, y, track_paths) = collect_data(dataset_path)\n",
    "    data = {'x': x, 'y': y, 'track_paths': track_paths}\n",
    "    with open('model/data.pkl','wb') as f:\n",
    "        _pickle.dump(data,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  blues\n",
      "Processing  classical\n",
      "Processing  country\n",
      "Processing  disco\n",
      "Processing  hiphop\n",
      "Processing  jazz\n",
      "Processing  metal\n",
      "Processing  pop\n",
      "Processing  reggae\n",
      "Processing  rock\n"
     ]
    }
   ],
   "source": [
    "generate_model('genres/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_model(data):\n",
    "    x = data['x']\n",
    "    y = data['y']\n",
    "    (x_train, x_val, y_train, y_val) = train_test_split(x, y,stratify=y, test_size=0.2,random_state=SEED)\n",
    "    print('Building Model...')\n",
    "    input_shape = (x_train.shape[1], x_train.shape[2])\n",
    "    print(input_shape)\n",
    "    model_input = Input(shape=input_shape)\n",
    "    layer = model_input\n",
    "    for i in range(3):\n",
    "        layer = Conv1D(filters=256, kernel_size=4,strides=2)(layer)\n",
    "        layer = Activation('relu')(layer)\n",
    "        layer = MaxPooling1D(2)(layer)\n",
    "    averagePool = GlobalAveragePooling1D()(layer)\n",
    "    maxPool = GlobalMaxPooling1D()(layer)\n",
    "    layer = concatenate([averagePool, maxPool])\n",
    "    layer = Dropout(rate=0.5)(layer)\n",
    "    layer = Dense(units=len(GENRES))(layer)\n",
    "    model_output = Activation('softmax')(layer)\n",
    "    model = Model(model_input, model_output)\n",
    "    opt = Adam()\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train,batch_size=BATCH_SIZE,epochs=80,validation_data=(x_val, y_val),verbose=1)\n",
    "    score=model.evaluate(x_val, y_val, verbose=1)\n",
    "    return model, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "N_LAYERS = 3\n",
    "FILTER_LENGTH = 5\n",
    "CONV_FILTER_COUNT = 256\n",
    "LSTM_COUNT = 256\n",
    "BATCH_SIZE = 32\n",
    "EPOCH_COUNT = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Model...\n",
      "(647, 128)\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/80\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 13.6508 - acc: 0.1050 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 2/80\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 3/80\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 4/80\n",
      "800/800 [==============================] - 7s 9ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 5/80\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 6/80\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 7/80\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 8/80\n",
      "800/800 [==============================] - 9s 12ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 9/80\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 10/80\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 11/80\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 12/80\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 13/80\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 14/80\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 15/80\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 16/80\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 17/80\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 18/80\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 19/80\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 20/80\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 21/80\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 22/80\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 23/80\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 24/80\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 25/80\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 26/80\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 27/80\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 28/80\n",
      "800/800 [==============================] - 12s 14ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 29/80\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 30/80\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 31/80\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 32/80\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 33/80\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 34/80\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 35/80\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 36/80\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 37/80\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 38/80\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 39/80\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 40/80\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 41/80\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 42/80\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 43/80\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 44/80\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 45/80\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 46/80\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 47/80\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 48/80\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 49/80\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 50/80\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 51/80\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 52/80\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 53/80\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 54/80\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 55/80\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 56/80\n",
      "800/800 [==============================] - 11s 14ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 57/80\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 58/80\n",
      "800/800 [==============================] - 9s 12ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 59/80\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 60/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 11s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 61/80\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 62/80\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 63/80\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 64/80\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 65/80\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 66/80\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 67/80\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 68/80\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 69/80\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 70/80\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 71/80\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 72/80\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 73/80\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 74/80\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 75/80\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 76/80\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 77/80\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 78/80\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 79/80\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 80/80\n",
      "800/800 [==============================] - 10s 13ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "200/200 [==============================] - 1s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "with open('model/data.pkl', 'rb') as pickle_file:\n",
    "    data = _pickle.load(pickle_file)\n",
    "model, score = get_cnn_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 647, 128)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 322, 256)     131328      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 322, 256)     0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 161, 256)     0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 79, 256)      262400      max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 79, 256)      0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 39, 256)      0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 18, 256)      262400      max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 18, 256)      0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 9, 256)       0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 256)          0           max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 256)          0           max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 512)          0           global_average_pooling1d_2[0][0] \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 512)          0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           5130        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 10)           0           dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 661,258\n",
      "Trainable params: 661,258\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weightedCustom(x):\n",
    "    weights=np.arange(77)\n",
    "    weights=weights[:,np.newaxis]\n",
    "    weightsKeras=K.variable(value=weights)\n",
    "    values_tensor=x\n",
    "    out=values_tensor*weights\n",
    "    out=K.sum(out,axis=1)\n",
    "    out=tf.divide(out,3003)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lstm_model(data):\n",
    "    x = data['x']\n",
    "    y = data['y']\n",
    "    (x_train, x_val, y_train, y_val) = train_test_split(x, y, test_size=0.3, random_state=SEED)\n",
    "\n",
    "    print ('Building model...')\n",
    "\n",
    "    n_features = x_train.shape[2]\n",
    "    input_shape = (None, n_features)\n",
    "    model_input = Input(input_shape, name='input')\n",
    "    layer = model_input\n",
    "    for i in range(N_LAYERS):\n",
    "        # convolutional layer names are used by extract_filters.py\n",
    "        layer = Convolution1D(\n",
    "                nb_filter=CONV_FILTER_COUNT,\n",
    "                filter_length=FILTER_LENGTH,\n",
    "                name='convolution_' + str(i + 1)\n",
    "            )(layer)\n",
    "        layer = Activation('relu')(layer)\n",
    "        layer = MaxPooling1D(2)(layer)\n",
    "\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = LSTM(LSTM_COUNT, return_sequences=True)(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = TimeDistributed(Dense(len(GENRES)))(layer)\n",
    "    layer = Activation('softmax', name='output_realtime')(layer)\n",
    "    time_distributed_merge_layer = Lambda(\n",
    "            function=lambda x: weightedCustom(x),\n",
    "            output_shape=lambda shape: (shape[0],) + shape[2:],\n",
    "            name='output_merged_weighted'\n",
    "        )\n",
    "    model_output = time_distributed_merge_layer(layer)\n",
    "    model = Model(model_input, model_output)\n",
    "    opt = RMSprop(lr=0.00001)\n",
    "    model.compile(\n",
    "            loss='categorical_crossentropy',\n",
    "            optimizer=opt,\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "    print ('Training...')\n",
    "    model.fit(x_train, y_train, batch_size=BATCH_SIZE, nb_epoch=EPOCH_COUNT, \n",
    "              validation_data=(x_val, y_val), verbose=1)\n",
    "    score=model.evaluate(x_val, y_val, verbose=1)\n",
    "    return model, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/willy/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(name=\"convolution_1\", filters=256, kernel_size=5)`\n",
      "/home/willy/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(name=\"convolution_2\", filters=256, kernel_size=5)`\n",
      "/home/willy/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(name=\"convolution_3\", filters=256, kernel_size=5)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/willy/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:43: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/100\n",
      "700/700 [==============================] - 31s 44ms/step - loss: 2.2341 - acc: 0.2129 - val_loss: 2.1363 - val_acc: 0.2433\n",
      "Epoch 2/100\n",
      "700/700 [==============================] - 32s 46ms/step - loss: 2.1288 - acc: 0.3100 - val_loss: 2.0302 - val_acc: 0.2633\n",
      "Epoch 3/100\n",
      "700/700 [==============================] - 33s 47ms/step - loss: 2.0265 - acc: 0.3529 - val_loss: 1.9527 - val_acc: 0.3100\n",
      "Epoch 4/100\n",
      "700/700 [==============================] - 33s 47ms/step - loss: 1.9540 - acc: 0.3943 - val_loss: 1.8810 - val_acc: 0.3233\n",
      "Epoch 5/100\n",
      "700/700 [==============================] - 35s 51ms/step - loss: 1.8916 - acc: 0.3843 - val_loss: 1.8288 - val_acc: 0.3600\n",
      "Epoch 6/100\n",
      "700/700 [==============================] - 36s 51ms/step - loss: 1.8335 - acc: 0.4057 - val_loss: 1.7844 - val_acc: 0.3300\n",
      "Epoch 7/100\n",
      "700/700 [==============================] - 37s 52ms/step - loss: 1.7816 - acc: 0.4000 - val_loss: 1.7532 - val_acc: 0.3200\n",
      "Epoch 8/100\n",
      "700/700 [==============================] - 36s 51ms/step - loss: 1.7278 - acc: 0.4186 - val_loss: 1.7054 - val_acc: 0.3433\n",
      "Epoch 9/100\n",
      "700/700 [==============================] - 38s 54ms/step - loss: 1.6883 - acc: 0.4486 - val_loss: 1.6978 - val_acc: 0.3600\n",
      "Epoch 10/100\n",
      "700/700 [==============================] - 36s 51ms/step - loss: 1.6599 - acc: 0.4400 - val_loss: 1.6670 - val_acc: 0.3667\n",
      "Epoch 11/100\n",
      "700/700 [==============================] - 36s 52ms/step - loss: 1.6231 - acc: 0.4657 - val_loss: 1.6511 - val_acc: 0.3600\n",
      "Epoch 12/100\n",
      "700/700 [==============================] - 36s 51ms/step - loss: 1.5887 - acc: 0.4657 - val_loss: 1.6086 - val_acc: 0.3733\n",
      "Epoch 13/100\n",
      "700/700 [==============================] - 36s 52ms/step - loss: 1.5569 - acc: 0.4900 - val_loss: 1.5874 - val_acc: 0.3733\n",
      "Epoch 14/100\n",
      "700/700 [==============================] - 36s 52ms/step - loss: 1.5270 - acc: 0.5029 - val_loss: 1.5482 - val_acc: 0.4200\n",
      "Epoch 15/100\n",
      "700/700 [==============================] - 37s 52ms/step - loss: 1.5100 - acc: 0.5129 - val_loss: 1.5415 - val_acc: 0.3867\n",
      "Epoch 16/100\n",
      "700/700 [==============================] - 37s 53ms/step - loss: 1.4748 - acc: 0.5314 - val_loss: 1.5331 - val_acc: 0.4067\n",
      "Epoch 17/100\n",
      "700/700 [==============================] - 37s 52ms/step - loss: 1.4524 - acc: 0.5386 - val_loss: 1.4951 - val_acc: 0.4067\n",
      "Epoch 18/100\n",
      "700/700 [==============================] - 36s 52ms/step - loss: 1.4251 - acc: 0.5514 - val_loss: 1.4855 - val_acc: 0.4167\n",
      "Epoch 19/100\n",
      "700/700 [==============================] - 36s 52ms/step - loss: 1.4043 - acc: 0.5614 - val_loss: 1.4648 - val_acc: 0.4200\n",
      "Epoch 20/100\n",
      "700/700 [==============================] - 37s 53ms/step - loss: 1.3820 - acc: 0.5571 - val_loss: 1.4556 - val_acc: 0.4367\n",
      "Epoch 21/100\n",
      "700/700 [==============================] - 36s 52ms/step - loss: 1.3573 - acc: 0.5757 - val_loss: 1.4405 - val_acc: 0.4433\n",
      "Epoch 22/100\n",
      "700/700 [==============================] - 36s 52ms/step - loss: 1.3412 - acc: 0.5643 - val_loss: 1.4157 - val_acc: 0.4500\n",
      "Epoch 23/100\n",
      "700/700 [==============================] - 37s 52ms/step - loss: 1.3100 - acc: 0.6029 - val_loss: 1.4053 - val_acc: 0.4833\n",
      "Epoch 24/100\n",
      "700/700 [==============================] - 37s 53ms/step - loss: 1.2929 - acc: 0.5986 - val_loss: 1.4084 - val_acc: 0.4567\n",
      "Epoch 25/100\n",
      "700/700 [==============================] - 37s 53ms/step - loss: 1.2770 - acc: 0.6057 - val_loss: 1.3724 - val_acc: 0.4367\n",
      "Epoch 26/100\n",
      "700/700 [==============================] - 36s 52ms/step - loss: 1.2625 - acc: 0.5957 - val_loss: 1.3519 - val_acc: 0.4933\n",
      "Epoch 27/100\n",
      "700/700 [==============================] - 36s 52ms/step - loss: 1.2439 - acc: 0.6000 - val_loss: 1.3485 - val_acc: 0.4667\n",
      "Epoch 28/100\n",
      "700/700 [==============================] - 38s 54ms/step - loss: 1.2293 - acc: 0.6057 - val_loss: 1.3290 - val_acc: 0.5033\n",
      "Epoch 29/100\n",
      "700/700 [==============================] - 36s 52ms/step - loss: 1.2133 - acc: 0.6286 - val_loss: 1.3129 - val_acc: 0.5067\n",
      "Epoch 30/100\n",
      "700/700 [==============================] - 37s 53ms/step - loss: 1.1879 - acc: 0.6114 - val_loss: 1.3078 - val_acc: 0.5033\n",
      "Epoch 31/100\n",
      "700/700 [==============================] - 36s 52ms/step - loss: 1.1774 - acc: 0.6271 - val_loss: 1.3019 - val_acc: 0.5000\n",
      "Epoch 32/100\n",
      "700/700 [==============================] - 35s 51ms/step - loss: 1.1621 - acc: 0.6429 - val_loss: 1.3043 - val_acc: 0.5133\n",
      "Epoch 33/100\n",
      "700/700 [==============================] - 36s 52ms/step - loss: 1.1419 - acc: 0.6557 - val_loss: 1.3080 - val_acc: 0.5033\n",
      "Epoch 34/100\n",
      "700/700 [==============================] - 37s 53ms/step - loss: 1.1195 - acc: 0.6743 - val_loss: 1.3047 - val_acc: 0.4967\n",
      "Epoch 35/100\n",
      "700/700 [==============================] - 35s 50ms/step - loss: 1.1179 - acc: 0.6400 - val_loss: 1.2484 - val_acc: 0.5200\n",
      "Epoch 36/100\n",
      "700/700 [==============================] - 37s 53ms/step - loss: 1.0952 - acc: 0.6671 - val_loss: 1.2498 - val_acc: 0.5200\n",
      "Epoch 37/100\n",
      "700/700 [==============================] - 37s 52ms/step - loss: 1.0805 - acc: 0.6757 - val_loss: 1.2592 - val_acc: 0.5267\n",
      "Epoch 38/100\n",
      "700/700 [==============================] - 37s 53ms/step - loss: 1.0707 - acc: 0.6743 - val_loss: 1.2381 - val_acc: 0.5233\n",
      "Epoch 39/100\n",
      "700/700 [==============================] - 36s 51ms/step - loss: 1.0514 - acc: 0.6814 - val_loss: 1.2251 - val_acc: 0.5567\n",
      "Epoch 40/100\n",
      "700/700 [==============================] - 37s 52ms/step - loss: 1.0514 - acc: 0.6829 - val_loss: 1.1948 - val_acc: 0.5467\n",
      "Epoch 41/100\n",
      "700/700 [==============================] - 36s 51ms/step - loss: 1.0362 - acc: 0.7014 - val_loss: 1.2305 - val_acc: 0.5267\n",
      "Epoch 42/100\n",
      "700/700 [==============================] - 39s 56ms/step - loss: 1.0216 - acc: 0.7000 - val_loss: 1.2036 - val_acc: 0.5500\n",
      "Epoch 43/100\n",
      "700/700 [==============================] - 36s 51ms/step - loss: 1.0069 - acc: 0.7043 - val_loss: 1.1944 - val_acc: 0.5567\n",
      "Epoch 44/100\n",
      "700/700 [==============================] - 37s 52ms/step - loss: 0.9896 - acc: 0.7043 - val_loss: 1.1782 - val_acc: 0.5700\n",
      "Epoch 45/100\n",
      "700/700 [==============================] - 36s 51ms/step - loss: 0.9770 - acc: 0.7029 - val_loss: 1.1907 - val_acc: 0.5533\n",
      "Epoch 46/100\n",
      "700/700 [==============================] - 36s 52ms/step - loss: 0.9743 - acc: 0.7043 - val_loss: 1.1721 - val_acc: 0.5567\n",
      "Epoch 47/100\n",
      "700/700 [==============================] - 37s 53ms/step - loss: 0.9542 - acc: 0.7057 - val_loss: 1.2048 - val_acc: 0.5567\n",
      "Epoch 48/100\n",
      "700/700 [==============================] - 36s 52ms/step - loss: 0.9581 - acc: 0.7000 - val_loss: 1.1528 - val_acc: 0.5567\n",
      "Epoch 49/100\n",
      "700/700 [==============================] - 36s 52ms/step - loss: 0.9432 - acc: 0.7143 - val_loss: 1.1551 - val_acc: 0.5667\n",
      "Epoch 50/100\n",
      "700/700 [==============================] - 37s 54ms/step - loss: 0.9082 - acc: 0.7414 - val_loss: 1.2186 - val_acc: 0.5367\n",
      "Epoch 51/100\n",
      "700/700 [==============================] - 36s 51ms/step - loss: 0.9064 - acc: 0.7386 - val_loss: 1.2001 - val_acc: 0.5567\n",
      "Epoch 52/100\n",
      "700/700 [==============================] - 37s 52ms/step - loss: 0.8950 - acc: 0.7286 - val_loss: 1.1888 - val_acc: 0.5700\n",
      "Epoch 53/100\n",
      "700/700 [==============================] - 37s 52ms/step - loss: 0.8892 - acc: 0.7357 - val_loss: 1.1695 - val_acc: 0.5400\n",
      "Epoch 54/100\n",
      "700/700 [==============================] - 36s 51ms/step - loss: 0.8872 - acc: 0.7443 - val_loss: 1.1721 - val_acc: 0.5633\n",
      "Epoch 55/100\n",
      "700/700 [==============================] - 37s 52ms/step - loss: 0.8673 - acc: 0.7314 - val_loss: 1.1312 - val_acc: 0.5733\n",
      "Epoch 56/100\n",
      "700/700 [==============================] - 36s 51ms/step - loss: 0.8508 - acc: 0.7543 - val_loss: 1.1168 - val_acc: 0.5833\n",
      "Epoch 57/100\n",
      "700/700 [==============================] - 37s 53ms/step - loss: 0.8364 - acc: 0.7500 - val_loss: 1.1705 - val_acc: 0.5700\n",
      "Epoch 58/100\n",
      "700/700 [==============================] - 37s 52ms/step - loss: 0.8407 - acc: 0.7700 - val_loss: 1.1524 - val_acc: 0.5800\n",
      "Epoch 59/100\n",
      "700/700 [==============================] - 35s 51ms/step - loss: 0.8230 - acc: 0.7557 - val_loss: 1.1410 - val_acc: 0.5933\n",
      "Epoch 60/100\n",
      "700/700 [==============================] - 37s 53ms/step - loss: 0.8234 - acc: 0.7614 - val_loss: 1.1488 - val_acc: 0.5800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "700/700 [==============================] - 36s 51ms/step - loss: 0.8205 - acc: 0.7543 - val_loss: 1.1267 - val_acc: 0.6033\n",
      "Epoch 62/100\n",
      "700/700 [==============================] - 36s 51ms/step - loss: 0.7903 - acc: 0.7686 - val_loss: 1.1521 - val_acc: 0.5767\n",
      "Epoch 63/100\n",
      "700/700 [==============================] - 36s 52ms/step - loss: 0.7832 - acc: 0.7886 - val_loss: 1.1259 - val_acc: 0.6000\n",
      "Epoch 64/100\n",
      "700/700 [==============================] - 35s 50ms/step - loss: 0.7897 - acc: 0.7786 - val_loss: 1.1130 - val_acc: 0.6033\n",
      "Epoch 65/100\n",
      "700/700 [==============================] - 36s 52ms/step - loss: 0.7599 - acc: 0.7814 - val_loss: 1.1668 - val_acc: 0.5767\n",
      "Epoch 66/100\n",
      "700/700 [==============================] - 37s 52ms/step - loss: 0.7720 - acc: 0.7786 - val_loss: 1.1152 - val_acc: 0.5900\n",
      "Epoch 67/100\n",
      "700/700 [==============================] - 36s 52ms/step - loss: 0.7473 - acc: 0.7786 - val_loss: 1.1545 - val_acc: 0.5800\n",
      "Epoch 68/100\n",
      "700/700 [==============================] - 37s 53ms/step - loss: 0.7445 - acc: 0.7871 - val_loss: 1.1608 - val_acc: 0.5700\n",
      "Epoch 69/100\n",
      "700/700 [==============================] - 35s 50ms/step - loss: 0.7346 - acc: 0.7800 - val_loss: 1.1117 - val_acc: 0.5967\n",
      "Epoch 70/100\n",
      "700/700 [==============================] - 37s 53ms/step - loss: 0.7167 - acc: 0.7986 - val_loss: 1.1003 - val_acc: 0.6233\n",
      "Epoch 71/100\n",
      "700/700 [==============================] - 36s 52ms/step - loss: 0.7152 - acc: 0.7857 - val_loss: 1.1136 - val_acc: 0.5900\n",
      "Epoch 72/100\n",
      "700/700 [==============================] - 36s 51ms/step - loss: 0.7140 - acc: 0.8057 - val_loss: 1.1265 - val_acc: 0.5800\n",
      "Epoch 73/100\n",
      "700/700 [==============================] - 38s 54ms/step - loss: 0.7062 - acc: 0.8014 - val_loss: 1.1479 - val_acc: 0.5767\n",
      "Epoch 74/100\n",
      "700/700 [==============================] - 36s 51ms/step - loss: 0.6919 - acc: 0.8086 - val_loss: 1.0904 - val_acc: 0.6233\n",
      "Epoch 75/100\n",
      "700/700 [==============================] - 37s 53ms/step - loss: 0.6793 - acc: 0.8129 - val_loss: 1.1313 - val_acc: 0.5867\n",
      "Epoch 76/100\n",
      "700/700 [==============================] - 36s 52ms/step - loss: 0.6751 - acc: 0.8043 - val_loss: 1.0881 - val_acc: 0.6333\n",
      "Epoch 77/100\n",
      "700/700 [==============================] - 37s 53ms/step - loss: 0.6702 - acc: 0.8157 - val_loss: 1.1285 - val_acc: 0.5933\n",
      "Epoch 78/100\n",
      "700/700 [==============================] - 36s 52ms/step - loss: 0.6494 - acc: 0.8329 - val_loss: 1.1060 - val_acc: 0.5967\n",
      "Epoch 79/100\n",
      "700/700 [==============================] - 37s 53ms/step - loss: 0.6441 - acc: 0.8314 - val_loss: 1.1499 - val_acc: 0.6000\n",
      "Epoch 80/100\n",
      "700/700 [==============================] - 36s 51ms/step - loss: 0.6449 - acc: 0.8200 - val_loss: 1.1307 - val_acc: 0.5967\n",
      "Epoch 81/100\n",
      "700/700 [==============================] - 36s 52ms/step - loss: 0.6368 - acc: 0.8271 - val_loss: 1.1043 - val_acc: 0.6100\n",
      "Epoch 82/100\n",
      "700/700 [==============================] - 36s 51ms/step - loss: 0.6209 - acc: 0.8500 - val_loss: 1.0778 - val_acc: 0.6567\n",
      "Epoch 83/100\n",
      "700/700 [==============================] - 37s 53ms/step - loss: 0.6150 - acc: 0.8243 - val_loss: 1.0882 - val_acc: 0.6167\n",
      "Epoch 84/100\n",
      "700/700 [==============================] - 36s 51ms/step - loss: 0.6143 - acc: 0.8429 - val_loss: 1.0936 - val_acc: 0.6333\n",
      "Epoch 85/100\n",
      "700/700 [==============================] - 36s 52ms/step - loss: 0.6128 - acc: 0.8443 - val_loss: 1.1587 - val_acc: 0.6200\n",
      "Epoch 86/100\n",
      "700/700 [==============================] - 36s 51ms/step - loss: 0.5931 - acc: 0.8429 - val_loss: 1.1612 - val_acc: 0.6000\n",
      "Epoch 87/100\n",
      "700/700 [==============================] - 36s 52ms/step - loss: 0.5930 - acc: 0.8500 - val_loss: 1.0744 - val_acc: 0.6300\n",
      "Epoch 88/100\n",
      "700/700 [==============================] - 36s 51ms/step - loss: 0.5824 - acc: 0.8586 - val_loss: 1.0935 - val_acc: 0.6333\n",
      "Epoch 89/100\n",
      "700/700 [==============================] - 36s 52ms/step - loss: 0.5786 - acc: 0.8486 - val_loss: 1.1006 - val_acc: 0.6333\n",
      "Epoch 90/100\n",
      "700/700 [==============================] - 37s 53ms/step - loss: 0.5706 - acc: 0.8600 - val_loss: 1.1214 - val_acc: 0.6200\n",
      "Epoch 91/100\n",
      "700/700 [==============================] - 37s 52ms/step - loss: 0.5696 - acc: 0.8357 - val_loss: 1.1121 - val_acc: 0.6400\n",
      "Epoch 92/100\n",
      "700/700 [==============================] - 36s 52ms/step - loss: 0.5596 - acc: 0.8671 - val_loss: 1.1350 - val_acc: 0.6267\n",
      "Epoch 93/100\n",
      "700/700 [==============================] - 37s 52ms/step - loss: 0.5389 - acc: 0.8771 - val_loss: 1.1488 - val_acc: 0.6133\n",
      "Epoch 94/100\n",
      "700/700 [==============================] - 36s 51ms/step - loss: 0.5490 - acc: 0.8557 - val_loss: 1.1082 - val_acc: 0.6333\n",
      "Epoch 95/100\n",
      "700/700 [==============================] - 36s 52ms/step - loss: 0.5284 - acc: 0.8686 - val_loss: 1.0710 - val_acc: 0.6400\n",
      "Epoch 96/100\n",
      "700/700 [==============================] - 37s 53ms/step - loss: 0.5238 - acc: 0.8786 - val_loss: 1.1799 - val_acc: 0.6267\n",
      "Epoch 97/100\n",
      "700/700 [==============================] - 35s 50ms/step - loss: 0.5214 - acc: 0.8686 - val_loss: 1.0496 - val_acc: 0.6533\n",
      "Epoch 98/100\n",
      "700/700 [==============================] - 37s 53ms/step - loss: 0.5177 - acc: 0.8771 - val_loss: 1.0876 - val_acc: 0.6533\n",
      "Epoch 99/100\n",
      "700/700 [==============================] - 38s 54ms/step - loss: 0.5053 - acc: 0.8829 - val_loss: 1.1068 - val_acc: 0.6500\n",
      "Epoch 100/100\n",
      "700/700 [==============================] - 36s 51ms/step - loss: 0.5075 - acc: 0.8743 - val_loss: 1.0806 - val_acc: 0.6467\n",
      "300/300 [==============================] - 5s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "with open('model/data.pkl', 'rb') as pickle_file:\n",
    "    data = _pickle.load(pickle_file)\n",
    "model, score = get_lstm_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6466666666666666\n"
     ]
    }
   ],
   "source": [
    "print(score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
