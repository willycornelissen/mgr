{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "import soundfile\n",
    "import pandas\n",
    "\n",
    "import librosa\n",
    "import soundfile\n",
    "from scipy.io.wavfile import read\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENRES = ['Blues', 'Classic', 'Country', 'Disco', 'Hiphop', 'Jazz', 'Metal', 'Pop', 'Reggae', 'Rock'] \n",
    "csv_columns=['mfcc1','mfcc2','mfcc3','mfcc4','mfcc5','mfcc6','mfcc7','mfcc8','mfcc9','mfcc10',\n",
    "             'mfcc11','mfcc12','mfcc13','mfcc14','mfcc15','centroid','flux','zcr','osc1','osc2','osc3',\n",
    "             'osc4','osc5','osc6','osc7','osc8','osc9','osc10','osc11','osc12','osc13','osc14','osc15',\n",
    "             'osc16','osc17','osc18','low','omsc1','omsc2','omsc3','omsc4','omsc5','omsc6','omsc7','omsc8',\n",
    "             'omsc9','omsc10','msfm1','msfm2','msfm3','msfm4','msfm5','msfm6','msfm7','msfm8','msfm9',\n",
    "             'msfm10','mscm1','mscm2','mscm3','mscm4','mscm5','mscm6','mscm7','mscm8','mscm9','mscm10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def melfilter (Fs,fftSize,totalfilters):\n",
    "    # Maximum frequency of filter (avoid aliasing)\n",
    "    maxF = Fs/2   \n",
    "\n",
    "    # Maximal Mel-frequency \n",
    "    maxMelF = 2595*np.log10(1+maxF/700)   \n",
    "    \n",
    "    # Scatter points in Mel-frequency scale\n",
    "    melpoints = np.arange(0,(totalfilters+2))/(totalfilters+1) * maxMelF\n",
    "    \n",
    "    # Convert points in normal frequency scale\n",
    "    points = 700*(10**(melpoints/2595)-1)\n",
    "    \n",
    "    # DTF bins within half fftSize\n",
    "    DFTbins = np.round(points/maxF*(fftSize/2)) \n",
    "    \n",
    "    # Set the first value to 1\n",
    "    DFTbins[0] = 1\n",
    "    \n",
    "    # Create an empty matrix to store filter\n",
    "    MelFilter = np.zeros((totalfilters,fftSize))\n",
    "    \n",
    "    # Create Triangle filters by each row (for MFCC)\n",
    "    for n in range (0,totalfilters):\n",
    "        low = int(DFTbins[n])           # Triangle start\n",
    "        center = int(DFTbins[n+1])      # Top of the Triangle\n",
    "        high = int(DFTbins[n+2])        # Triangle end\n",
    "        \n",
    "        UpSlope = center-low       # Number of DFT points in lower side of Triangle\n",
    "        DownSlope = high-center    # Number of DFT points in upper side of Triangle\n",
    "        \n",
    "        # Create lower side slope\n",
    "        MelFilter[n,range(low-1,center)] = np.arange(0,UpSlope+1)/UpSlope       \n",
    "        \n",
    "        # Create upper side slope\n",
    "        MelFilter[n,range(center-1,high)] = np.flipud(np.arange(0,DownSlope+1)/DownSlope)  \n",
    "        \n",
    "    return MelFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zerocrossing (xw):\n",
    "    \n",
    "    # Size of windowed signal\n",
    "    wsize = len(xw)\n",
    "    \n",
    "    # Slided signal\n",
    "    xw2 = np.zeros(wsize)\n",
    "    xw2[1:] = xw[0:-1]\n",
    "    \n",
    "    # Compute Zero-crossing Rate\n",
    "    z = (1/(2*wsize)) * sum(abs(np.sign(xw)-np.sign(xw2)))\n",
    "    \n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dctmatrix (totalfilters,mfcccoeff):\n",
    "    \n",
    "    # Create an matrix (mfcccoeff * totalfilters)\n",
    "    [cc,rr] = np.meshgrid(range(0,totalfilters), range(0,mfcccoeff))\n",
    "    \n",
    "    # Calculate DCT\n",
    "    c = np.sqrt(2 / totalfilters) * np.cos(math.pi * (2*cc + 1) * rr / (2 * totalfilters))\n",
    "    c[0,:] = c[0,:] / np.sqrt(2)                     \n",
    "    \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroid (X1,fftSize,Fs):\n",
    "    \n",
    "    # Calculate frequency bins\n",
    "    k = (Fs/fftSize)*np.arange(0,int(fftSize/2))\n",
    "\n",
    "    # Calculate Spectral Centroid\n",
    "    c = sum(k*X1)/sum(X1)\n",
    "\n",
    "    # Normalise by Fs/2\n",
    "    c = c/(Fs/2)\n",
    "    \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolloff (param,X1):\n",
    "    \n",
    "    # Initialize energy and FFT number\n",
    "    Energy = 0\n",
    "    Count = 0\n",
    "    \n",
    "    # Find Count which has energy below param*TotalEnergy \n",
    "    TotalEnergy = sum(X1**2)\n",
    "    \n",
    "    # Find Count which has energy below param*TotalEnergy \n",
    "    while Energy <= param*TotalEnergy and Count < len(X1):\n",
    "        Energy = X1[Count]**2 + Energy\n",
    "        Count += 1\n",
    "        \n",
    "    # Adjust the order\n",
    "    r = Count - 1\n",
    "    \n",
    "    # Normalise Spectral Rolloff\n",
    "    r = r/len(X1)\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def osc (Fs,X1,fftSize,alpha):\n",
    "    \n",
    "    # Indicate frequency points to create bins\n",
    "    Subband_points = [0,100,200,400,800,1600,3200,6400,12800,Fs/2]\n",
    "    \n",
    "    # FFT bins within half fftSize\n",
    "    SubFFTbins = np.round(np.divide(Subband_points,Fs/2)*fftSize/2) \n",
    "\n",
    "    # Set the first value to 1\n",
    "    SubFFTbins[0] = 1\n",
    "\n",
    "    # Create empty matrices for peak, valley and sum for each band\n",
    "    peak = np.zeros(len(Subband_points)-1)\n",
    "    valley = np.zeros(len(Subband_points)-1)\n",
    "    Xsum = np.zeros(len(Subband_points)-1)\n",
    "\n",
    "    # Take peaks and valleys from all FFT frames\n",
    "    for b in range (0,len(Subband_points)-1):   \n",
    "        Xframe = X1[int(SubFFTbins[b]):int(SubFFTbins[b+1])]     # Take out FFT frame\n",
    "        Xsmall2big = np.sort(Xframe)                             # Sort values from small to big\n",
    "        Xbig2small = np.flipud(Xsmall2big)                       # Sort values from big to small\n",
    "        N = int(np.round(alpha*len(Xframe)))                     # Take values up to N in each frame\n",
    "        peak[b] = math.log10((1/N)*sum(Xbig2small[0:N]))         # Calculate peak from each frame\n",
    "        valley[b] = math.log10((1/N)*sum(Xsmall2big[0:N]))       # Calculate valley from each frame\n",
    "        Xsum[b] = sum(Xframe)                                    # Sum of power spectrum from each sub-band\n",
    "        Xsum.transpose\n",
    "\n",
    "    # Take difference (ignore the first value)\n",
    "    sc = peak[:] - valley[:]\n",
    "\n",
    "    # Cobmine features\n",
    "    o = np.hstack((valley[:],sc))\n",
    "    \n",
    "    return o,Xsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datacleaner(RawData,mode,rc):\n",
    "    \n",
    "    # Case of vector input data\n",
    "    if RawData.ndim == 1:\n",
    "        NaNData = np.zeros(len(RawData))\n",
    "        InfData = NaNData\n",
    "        \n",
    "        if mode == 0:\n",
    "            for i in range(0,len(RawData)):\n",
    "                NaNData[i] = math.isnan(RawData[i])\n",
    "                InfData[i] = math.isinf(RawData[i])\n",
    "        BrokenData = NaNData + InfData\n",
    "        ValidDataIdx = np.nonzero(BrokenData == 0)[0]\n",
    "        ValidData = RawData[ValidDataIdx]\n",
    "        \n",
    "        if mode == 1:\n",
    "            for i in range(0,len(RawData)):\n",
    "                NaNData[i] = math.isnan(RawData[i])\n",
    "        BrokenData = NaNData\n",
    "        ValidDataIdx = np.nonzero(BrokenData == 0)[0]\n",
    "        ValidData = RawData[ValidDataIdx]\n",
    "        \n",
    "        if mode == 2:\n",
    "            for i in range(0,len(InfData)):\n",
    "                InfData[i] = math.isnan(RawData[i])\n",
    "        BrokenData = InfData\n",
    "        ValidDataIdx = np.nonzero(BrokenData == 0)[0]\n",
    "        ValidData = RawData[ValidDataIdx]\n",
    "        \n",
    "    # Case of matrix input data\n",
    "    if RawData.ndim ==  2:\n",
    "        \n",
    "        if mode == 0:\n",
    "        # Check data for each row\n",
    "            for r in range(0,((RawData.shape)[0])):\n",
    "                for c in range(0,((RawData.shape)[1])):\n",
    "                    # Replace Inf as NaN\n",
    "                    if math.isinf(RawData[r,c]) == 1:\n",
    "                        RawData[r,c] = np.nan\n",
    "            # Exclude colmun/row including NaN\n",
    "            if rc == 0: \n",
    "                ValidData = RawData[~np.isnan(RawData).any(axis=1)]             # Exclude Row\n",
    "            if rc == 1:\n",
    "                ValidData = np.ma.compress_cols(np.ma.masked_invalid(RawData))  # Exclude Column\n",
    "                \n",
    "        if mode == 1:\n",
    "            if rc == 0:\n",
    "                ValidData = RawData[~np.isnan(RawData).any(axis=1)]             # Exclude Row\n",
    "            if rc == 1:\n",
    "                ValidData = np.ma.compress_cols(np.ma.masked_invalid(RawData))  # Exclude Column\n",
    "    \n",
    "        if mode == 2:\n",
    "            if rc == 0:\n",
    "                ValidData = RawData[~np.isinf(RawData).any(axis=1)]             # Exclude Row\n",
    "            if rc == 1:\n",
    "                ValidData = np.ma.compress_cols(np.ma.masked_invalid(RawData))  # Exclude Column\n",
    "    \n",
    "    return ValidData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(Data,type):\n",
    "    \n",
    "    # Check dimension\n",
    "    Dim = Data.ndim\n",
    "    \n",
    "    # Create an empty matrix\n",
    "    NormData = np.zeros((Data.shape[0],Data.shape[1]))\n",
    "    \n",
    "    # Case of vector input\n",
    "    if Dim == 1:\n",
    "        for n in range(0,Data.shape[0]):\n",
    "            Data = (Data-min(Data))/(max(Data)-min(Data))\n",
    "            \n",
    "    # Case of matrix input\n",
    "    else:\n",
    "        \n",
    "    # Normalise by column\n",
    "        if type == 0:\n",
    "            for n in range(0,Data.shape[1]):\n",
    "                DataColumn = Data[:,n]\n",
    "                DataColumn = (DataColumn-min(DataColumn))/(max(DataColumn)-min(DataColumn))\n",
    "                NormData[:,n] = DataColumn\n",
    "                \n",
    "    # Normalise by row\n",
    "        else:\n",
    "            for m in range(0,Data.shape[0]):\n",
    "                DataRow = Data[m,:]\n",
    "                DataRow = (DataRow-min(DataRow))/(max(DataRow)-min(DataRow))\n",
    "                NormData[m,:] = DataRow\n",
    "                \n",
    "    return NormData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardise(Data,type):\n",
    "    \n",
    "    # Check dimension\n",
    "    Dim = Data.ndim\n",
    "    \n",
    "    # Create an empty matrix\n",
    "    StdData = np.zeros((Data.shape[0],Data.shape[1]))\n",
    "    \n",
    "    # Case of vector input\n",
    "    if Dim == 1:\n",
    "        for n in range(0,Data.shape[0]):\n",
    "            Data = (Data-min(Data))/(max(Data)-min(Data))\n",
    "            \n",
    "    # Case of matrix input\n",
    "    else:\n",
    "        \n",
    "    # Standardise by column\n",
    "        if type == 0:\n",
    "            for n in range(0,Data.shape[1]):\n",
    "                DataColumn = Data[:,n]\n",
    "                DataColumn = (DataColumn-np.mean(DataColumn))/np.std(DataColumn)\n",
    "                StdData[:,n] = DataColumn\n",
    "                \n",
    "    # Standardise by row\n",
    "        else:\n",
    "            for m in range(0,Data.shape[0]):\n",
    "                DataRow = Data[m,:]\n",
    "                DataRow = (DataRow-np.mean(DataRow))/np.std(DataRow)\n",
    "                StdData[m,:] = DataRow\n",
    "                \n",
    "    return StdData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cs_features(file_name):\n",
    "    ## Variable declaration for features\n",
    "\n",
    "    # Number of mfccs (+1 in order to truncate the first coefficient)\n",
    "    mfcccoeff = 15\n",
    "    mfcccoeff = mfcccoeff + 1\n",
    "\n",
    "    # Number of Octave based sub-bands\n",
    "    b = 8\n",
    "\n",
    "    # FFT size\n",
    "    fftsize = 4096\n",
    "\n",
    "    # Number of filters for mel-filter\n",
    "    totalfilters = 40\n",
    "\n",
    "    # Sampling frequency\n",
    "    Fs = 44100\n",
    "\n",
    "    # Length of analysis window\n",
    "    windowtime = 46.44\n",
    "\n",
    "    # Samples in one analysis window\n",
    "    windowsample = math.floor((windowtime/1000) * Fs)\n",
    "\n",
    "    # Overlap for window\n",
    "    overlaptime = 0.5 * windowtime\n",
    "\n",
    "    # Window step\n",
    "    windowstep = math.floor(Fs*((windowtime-overlaptime)/1000))\n",
    "\n",
    "    # Melfilter\n",
    "    MelFilter = melfilter(Fs,fftsize,totalfilters)\n",
    "\n",
    "    # DCT Matrix\n",
    "    c = dctmatrix(totalfilters,mfcccoeff)\n",
    "\n",
    "    # Number of Octave based sub-bands\n",
    "    b = 9\n",
    "\n",
    "    # Parameters for Octave based Spectral Contrast\n",
    "    alpha = 0.2\n",
    "\n",
    "    # Size of modulation spectrum\n",
    "    fftsize1 = 512\n",
    "\n",
    "    # Number of sub-band for modulation spectrum\n",
    "    J = 8\n",
    "\n",
    "    # Silence Removal (0:Off,1:On)\n",
    "    Srem = 1\n",
    "\n",
    "    # Variable for modulation spectrum\n",
    "    valley = np.zeros(J)\n",
    "    contrast = np.zeros(J)\n",
    "    \n",
    "    # Load audio data\n",
    "    # fs, x = read(file_name)\n",
    "    x, fs = soundfile.read(file_name, dtype='float32')\n",
    "\n",
    "    # Extract one channel (0:left, 1:right) if audio file is stereo\n",
    "    if x.ndim == 2:\n",
    "        x = x[:,0]\n",
    "\n",
    "    # Normalize audio input\n",
    "    audio = x/max(abs(x[:]))\n",
    "    \n",
    "    AFrameNum = int(np.floor((len(x)-windowstep)/windowstep))\n",
    "    TFrameNum = 10\n",
    "    Audiomatrix = np.zeros((windowsample,AFrameNum))\n",
    "    \n",
    "    # Silence Removal\n",
    "    Valid = np.zeros(AFrameNum)\n",
    "    for i in range(0,AFrameNum):\n",
    "        StartAnalysis = i*windowstep                       # Start sample of frame\n",
    "        EndAnalysis = StartAnalysis + windowsample         # End sample of frame\n",
    "        Audiomatrix[:,i] = audio[StartAnalysis:EndAnalysis]\n",
    "        Nonzeros = np.size((abs(audio[StartAnalysis:EndAnalysis]) > 0.0001).nonzero())    # Number of zeros in a frame\n",
    "        if Nonzeros > len(audio[StartAnalysis:EndAnalysis])/2:\n",
    "             Valid[i] = 1                                  # Valid only frames have samples more than half of frames\n",
    "\n",
    "        # Extract only valid frames\n",
    "        ValidFrames = np.flatnonzero(Valid)           # Number of valid frames\n",
    "        AFrameNum = np.size(ValidFrames)         # New analysis frame number\n",
    "\n",
    "    # Number of analysis windows in a texture window\n",
    "    t = np.floor(AFrameNum/TFrameNum)\n",
    "\n",
    "    # Create an empty matrix to store MFCC\n",
    "    MFCC = np.zeros((mfcccoeff, AFrameNum))\n",
    "\n",
    "    # Create an empty matrix to store spectrogram\n",
    "    Spectrogram = np.zeros((int(fftsize/2), AFrameNum))\n",
    "\n",
    "    # Create an empty matrix to store Melspectrogram\n",
    "    Melspectrogram = np.zeros((int(fftsize/2), AFrameNum))\n",
    "\n",
    "    # Create an empty matrix to store Spectral centroid\n",
    "    Centroid = np.zeros(AFrameNum)\n",
    "\n",
    "    # Create an empty matrix to store Spectral Rolloff\n",
    "    Rolloff = np.zeros(AFrameNum)\n",
    "\n",
    "    # Create an empty matrix to store Spectral Flux\n",
    "    Flux = np.zeros(AFrameNum)\n",
    "    X1Prev = np.zeros(int(fftsize/2))\n",
    "\n",
    "    # Create an empty matrix to store Zero-Crossing Rate\n",
    "    ZCR = np.zeros(AFrameNum)\n",
    "\n",
    "    # Create an empty matrix to store Octave-based Spectral Contrast\n",
    "    OSC = np.zeros((b*2,AFrameNum))\n",
    "\n",
    "    # Create an empty vector to store sum of power spectrum in sub-bands\n",
    "    XSum = np.zeros((b,AFrameNum))\n",
    "\n",
    "    # Create an empty matrix to store Root Mean Square Energy and Low Energy\n",
    "    RMSAnalysis = np.zeros(AFrameNum)\n",
    "\n",
    "    Low = np.zeros(TFrameNum)\n",
    "    OMSC = np.zeros((2*J,TFrameNum))\n",
    "    MSFM = np.zeros((J,TFrameNum))\n",
    "    MSCM = np.zeros((J,TFrameNum))\n",
    "\n",
    "    # FFT bins equally distributed\n",
    "    MScalebinstep = (fftsize1/2/J)\n",
    "\n",
    "    # Create empty matrices to store long term features\n",
    "    MFCC_Mean = np.zeros((mfcccoeff,TFrameNum))\n",
    "    Centroid_Mean = np.zeros(TFrameNum)\n",
    "    Rolloff_Mean = np.zeros(TFrameNum)\n",
    "    Flux_Mean = np.zeros(TFrameNum)\n",
    "    ZCR_Mean = np.zeros(TFrameNum)\n",
    "    OSC_Mean = np.zeros((2*b,TFrameNum))\n",
    "    \n",
    "    # FFT to entire audio file\n",
    "    Spectrum = np.absolute(np.fft.fft(audio[0:fftsize]))\n",
    "    \n",
    "    #============================================================================\n",
    "    # Short Term Features (Analysis Window)\n",
    "    #============================================================================\n",
    "    \n",
    "    \n",
    "    for n in range(0,AFrameNum):\n",
    "        \n",
    "        # Windowing\n",
    "        xw = Audiomatrix[:,ValidFrames[n]] * np.hamming(windowsample)\n",
    "        \n",
    "        # Spectrum\n",
    "        X = abs(np.fft.fft(xw,n=fftsize))\n",
    "        \n",
    "        # Normalise\n",
    "        X1 = X / math.sqrt(fftsize*windowsample)\n",
    "        \n",
    "        # Compute Root Mean Square Energy\n",
    "        RMSAnalysis[n] = math.sqrt(1/len(xw)*sum(xw**2))\n",
    "        \n",
    "        # Compute Zero-Crossing Rate\n",
    "        ZCR[n] = zerocrossing(xw)\n",
    "        \n",
    "        # Trancate half of spectrum\n",
    "        X1 = X1[0:int(fftsize/2)]\n",
    "        \n",
    "        # Compute Spectral Centroid\n",
    "        Centroid[n] = centroid(X1,fftsize,Fs)\n",
    "        \n",
    "        # Compute Spectral Rolloff\n",
    "        Rolloff[n] = rolloff(0.89,X1)\n",
    "        \n",
    "        # Compute Spectral Flux\n",
    "        Flux[n] = math.sqrt((sum((X1 - X1Prev)**2))/(Fs/2))\n",
    "        \n",
    "        # Compute Octave-based Spectral Contrast\n",
    "        [OSC[:,n],XSum[:,n]] = osc(Fs,X1,fftsize,alpha)\n",
    "        \n",
    "        #Store FFT result\n",
    "        X1Prev = X1\n",
    "        \n",
    "        # Apply Mel scale filter\n",
    "        Melfft = np.matmul(MelFilter,X)\n",
    "        \n",
    "        # Log scale\n",
    "        earMag = np.log10(Melfft**2)\n",
    "        \n",
    "        # Apply DCT to cepstrum\n",
    "        M = c.dot(earMag)\n",
    "        \n",
    "        #Store MFCC into matrix\n",
    "        MFCC[:,n] = M\n",
    "        \n",
    "    # Remove useless data\n",
    "    MFCC = datacleaner(MFCC,0,0)\n",
    "    RMSAnalysis = datacleaner(RMSAnalysis,0,0)\n",
    "    Centroid = datacleaner(Centroid,0,0)\n",
    "    Rolloff = datacleaner(Rolloff,0,0)\n",
    "    Flux = datacleaner(Flux,0,0)\n",
    "    ZCR = datacleaner(ZCR,0,0)\n",
    "    OSC = datacleaner(OSC,0,0)\n",
    "    \n",
    "    #============================================================================\n",
    "    # Long Term Features (Texture Window)\n",
    "    #============================================================================\n",
    "    \n",
    "    # For each texture window\n",
    "    for l in range(0,TFrameNum):\n",
    "        StartTexture = int(l*t)                      # Start point of texture window\n",
    "        EndTexture = int(StartTexture + t)           # End point of texture window\n",
    "\n",
    "        if EndTexture >= AFrameNum:\n",
    "            EndTexture = AFrameNum-1           # End analysis window to avoid exceeding Analysis frame length\n",
    "\n",
    "        # Average of RMS energy in texture window\n",
    "        RMSAverage = np.mean(RMSAnalysis[StartTexture:EndTexture])\n",
    "\n",
    "        # Store RMS energy from analysis window into texture window\n",
    "        LowRMS = (RMSAverage > RMSAnalysis[StartTexture:EndTexture])\n",
    "\n",
    "        if len(RMSAnalysis[StartTexture:EndTexture]) == 0:\n",
    "            Low[l] = np.nan\n",
    "        else:\n",
    "        # Compute Low Energy\n",
    "            Low[l] = (sum(LowRMS)/len(RMSAnalysis[StartTexture:EndTexture]))*100\n",
    "\n",
    "        # Sum of power spectrum in Sub-band across texture window (8*32)\n",
    "        T = np.arange(StartTexture,EndTexture)\n",
    "        E = XSum[:,StartTexture:EndTexture]\n",
    "        Epadded = np.hstack((E,np.zeros((b,fftsize1-len(T)))))   # Zero padding to make 512 length vector\n",
    "\n",
    "        M = abs(np.fft.fft(Epadded,n=fftsize1,axis=1))           # Apply fft to each row to get modulation spectrum\n",
    "        M = M[:,0:int(fftsize1/2)]                               # Truncate half\n",
    "\n",
    "        for jj in range(0,J):\n",
    "            Mb = M[jj,:]\n",
    "            Start = int(jj*MScalebinstep)\n",
    "            End = int(Start+MScalebinstep)\n",
    "            Mframe = Mb[Start:End]                                         # Take out FFT frame\n",
    "            peak = max(np.log10(Mframe[:]))                                # Calculate peaks from each frame\n",
    "            minimum = min(np.log10(Mframe[:]))                             # Calculate valley from each frame\n",
    "            valley[jj] = min(np.log10(Mframe[1:round(MScalebinstep/2)]))   # Search valley from first half frame\n",
    "            contrast[jj] = peak - minimum                                  # Calculate contrast\n",
    "\n",
    "        # Combine features to create Octave-based Modulation Spectral Contrast\n",
    "        OMSC[:,l] = np.hstack((contrast,valley))\n",
    "\n",
    "        def geo_mean(iterable):\n",
    "            a = np.log(iterable)\n",
    "            return np.exp(a.sum()/len(a))\n",
    "\n",
    "        for k in range(0,b-1):\n",
    "            MSFM[k,l] = geo_mean(M[k,:])/np.mean(M[k,:])\n",
    "            MSCM[k,l] = max(M[k,:])/np.mean(M[k,:])   \n",
    "            \n",
    "        # Compute long-term features (From Texture window)\n",
    "        MFCC_Mean[:,l] = np.mean(MFCC[:,StartTexture:EndTexture],axis=1)\n",
    "        Centroid_Mean[l] = np.mean(Centroid[StartTexture:EndTexture])\n",
    "        Rolloff_Mean[l] = np.mean(Rolloff[StartTexture:EndTexture])\n",
    "        Flux_Mean[l] = np.mean(Flux[StartTexture:EndTexture])\n",
    "        ZCR_Mean[l] = np.mean(ZCR[StartTexture:EndTexture])\n",
    "        OSC_Mean[:,l] = np.mean(OSC[:,StartTexture:EndTexture],axis=1) \n",
    "        \n",
    "    MFCC = np.mean(MFCC_Mean,axis=1)\n",
    "    MFCC = MFCC[1:]\n",
    "    Centroid = np.mean(Centroid_Mean)\n",
    "    Rolloff = np.mean(Rolloff_Mean)\n",
    "    Flux = np.mean(Flux_Mean)\n",
    "    ZCR = np.mean(ZCR_Mean)\n",
    "    OSC = np.mean(OSC_Mean,axis=1)\n",
    "    Low = np.mean(Low,axis=0)\n",
    "    OMSC = np.mean(OMSC,axis=0)\n",
    "    MSFM = np.mean(MSFM,axis=0)\n",
    "    MSCM = np.mean(MSCM,axis=0)\n",
    "\n",
    "    return MFCC, Centroid, Rolloff, Flux, ZCR, OSC, Low, OMSC, MSFM, MSCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_audio_files(path):\n",
    "    genres = os.listdir(path)\n",
    "    list_features = []\n",
    "    normalization = True\n",
    "    standardization = False\n",
    "\n",
    "    \n",
    "    columns_features = ['MFCC','Centroid','Rolloff','Flux','Zero Crossing Rate','OSC',\n",
    "                        'Low Energy','OMSC','MSFM','MSCM','Genre']\n",
    "    print(\"Extracting CS Features:\", path)\n",
    "    genreId = 0\n",
    "    labelId = 0\n",
    "    genres=sorted(os.listdir('genres'))\n",
    "    for genre in genres:\n",
    "        print(\"Processing\", GENRES[genreId])\n",
    "        files = os.listdir(os.path.join(path,genre))\n",
    "        # Create label vector\n",
    "        labelId = labelId + 1\n",
    "        label = labelId*np.ones(len(files))\n",
    "        label = np.array([label]).T\n",
    "        fileId = 0\n",
    "        for file in sorted(files):\n",
    "            \n",
    "            # Process one file\n",
    "            try:\n",
    "                featurelist = extract_cs_features(os.path.join(path,genre,file))\n",
    "            except Exception as e:\n",
    "                print(\"Error CS-Features Extracton:\", file,\" - \", e)\n",
    "                \n",
    "            # Append to list of files processed\n",
    "            featurefile = []\n",
    "            for i in featurelist:\n",
    "                featurefile = np.append(featurefile,i)\n",
    "            if fileId == 0:\n",
    "                featuregenre = np.zeros(len(featurefile))\n",
    "            featuregenre = np.vstack([featuregenre,featurefile])\n",
    "            fileId = fileId + 1\n",
    "         # Transpose feature matrix and add label   \n",
    "        featuregenre = featuregenre[1:]\n",
    "        featuregenre = np.hstack([featuregenre, label])\n",
    "        if genreId == 0:\n",
    "            feature_set = np.zeros(len(featurefile)+1)\n",
    "        feature_set = np.vstack([feature_set, featuregenre])\n",
    "        genreId = genreId + 1\n",
    "    # Extract first row                           \n",
    "    feature_set = feature_set[1:]\n",
    "\n",
    "    Data = pandas.DataFrame(feature_set)\n",
    "    if normalization:\n",
    "        Content = Data.iloc[:,0:Data.shape[1]-1]\n",
    "        Content = pandas.DataFrame(normalise(Content.values,0))\n",
    "    elif standardization:\n",
    "        Content = Data.iloc[:,0:Data.shape[1]-1]\n",
    "        Content = pandas.DataFrame(standardise(Content.values,0))\n",
    "    Label = Data.iloc[:,Data.shape[1]-1]\n",
    "    # Combine data and label\n",
    "    Data = pandas.concat([Content, Label], axis=1)\n",
    "    Data.to_csv(\"Data.csv\")                       \n",
    "    return Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting CS Features: genres\n",
      "Processing Blues\n",
      "Processing Classic\n",
      "Processing Country\n",
      "Processing Disco\n",
      "Processing Hiphop\n",
      "Processing Jazz\n",
      "Processing Metal\n",
      "Processing Pop\n",
      "Processing Reggae\n",
      "Processing Rock\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-aa488bad2dc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mread_audio_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'genres'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mhours\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdivmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mminutes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseconds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdivmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-3df16044cbf9>\u001b[0m in \u001b[0;36mread_audio_files\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mContent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "read_audio_files('genres')\n",
    "end=time.time()\n",
    "hours, rem = divmod(end-start, 3600)\n",
    "minutes, seconds = divmod(rem, 60)\n",
    "print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "MFCC, Centroid, Rolloff, Flux, ZCR, OSC, Low, OMSC, MSFM, MSCM = extract_cs_features('genres/blues/blues.00000.au')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04367531,  0.09216841,  0.17296579,  0.01585511,  0.02580731,\n",
       "        0.07876983,  0.02600801,  0.10906518,  0.09000139, -0.03973897])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OMSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.59896432, 0.57865094, 0.61444782, 0.62149684, 0.58059561,\n",
       "       0.61714264, 0.63403186, 0.59722419, 0.61230143, 0.56350734])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11.90306969, 12.70497113, 11.9699923 , 12.06658073, 12.8160616 ,\n",
       "       12.43354347, 11.38132248, 12.28464662, 11.96883226, 12.40417233])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.38790557, -2.99475077, -2.99404734, -3.26718041, -3.48400588,\n",
       "       -3.79311184, -3.96553023, -4.31332487, -5.76425577,  0.97782874,\n",
       "        0.86201982,  0.92695163,  1.09837241,  1.19259889,  1.1241326 ,\n",
       "        1.04948425,  0.92731685,  1.93774632])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
